{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eda3ff38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torchvision\n",
    "from torch.utils import data\n",
    "from torchvision import transforms\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "trans = transforms.ToTensor()\n",
    "# 创建Dataset对象\n",
    "mnist_train = torchvision.datasets.FashionMNIST(root=\"../data/\",train=True,transform=trans,download=True)\n",
    "mnist_test = torchvision.datasets.FashionMNIST(root=\"../data/\",train=False,transform=trans,download=True) \n",
    "\n",
    "train_iter = data.DataLoader(mnist_train, batch_size, shuffle=True, num_workers=4) # 加载数据并分批\n",
    "test_iter = data.DataLoader(mnist_test, batch_size, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a33a366b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_train[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0011048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-9.9251e-03,  3.9568e-03,  3.0540e-03,  ...,  3.5584e-03,\n",
      "          7.1917e-03, -3.2820e-03],\n",
      "        [-8.4160e-03,  9.1574e-03, -5.0447e-07,  ..., -8.3311e-03,\n",
      "          5.6575e-04, -9.9625e-05],\n",
      "        [ 1.1982e-02, -1.6683e-03,  3.1474e-03,  ..., -1.1207e-02,\n",
      "         -7.9860e-04, -1.6032e-02],\n",
      "        ...,\n",
      "        [ 5.0406e-03,  9.9460e-03,  6.5048e-03,  ...,  1.3254e-04,\n",
      "          1.7051e-02,  2.1368e-03],\n",
      "        [-1.0665e-02, -7.0885e-03,  1.3447e-02,  ..., -3.0942e-03,\n",
      "          3.2712e-04,  1.4247e-02],\n",
      "        [ 1.1700e-02,  4.8642e-03, -5.4011e-04,  ..., -1.0139e-02,\n",
      "         -6.0516e-03,  1.4365e-02]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Softmax回归的输出是一个全连接层\n",
    "# PyTorch不会隐式地调整输入的形状\n",
    "# 因此，我们定义了展平层(flatten)在线性层前调整网络输入的形状\n",
    "# Flaten():将任意维度的tensor转换为2d维度的tensor\n",
    "net = nn.Sequential(nn.Flatten(), nn.Linear(784, 10)) # 1*28*28\n",
    "\n",
    "def init_weight(m): # m为当前的layer\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.normal_(m.weight, std = 0.01) # 标准差\n",
    "\n",
    "net.apply(init_weight) # 对网络的每一层实施初始化\n",
    "print(net[1].weight) # 注意Flatten层是没有参数的，只有Linear层才有参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18193e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在交叉熵损失函数中传递未归一化的预测，并同时计算softmax及其对数\n",
    "loss = nn.CrossEntropyLoss()\n",
    "# * nn.CrossEntropyLoss 在计算损失时的一个关键点。\n",
    "# *当你给它传入一个 batch（批量） 的预测值 net(X) 和真实标签 y 时，\n",
    "# *它会计算这个批量中每个样本的损失，然后默认会取这些损失的平均值。\n",
    "# 设置优化算法：小批量随机梯度下降\n",
    "trainer = torch.optim.SGD(net.parameters(), lr=0.1) # 传入net的所有参数，设置学习率\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac3b6bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1,cost:0.552619, accuracy:0.8510\n",
      "epoch:2,cost:0.358660, accuracy:0.8511\n",
      "epoch:3,cost:0.445071, accuracy:0.8493\n",
      "epoch:4,cost:0.268670, accuracy:0.8494\n",
      "epoch:5,cost:0.405321, accuracy:0.8497\n",
      "epoch:6,cost:0.324140, accuracy:0.8493\n",
      "epoch:7,cost:0.592218, accuracy:0.8489\n",
      "epoch:8,cost:0.557565, accuracy:0.8472\n",
      "epoch:9,cost:0.411822, accuracy:0.8481\n",
      "epoch:10,cost:0.353706, accuracy:0.8486\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "num_correct = 0\n",
    "train_loss = 0\n",
    "num_samples = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for X, y in train_iter:  # 从DataLoader里面一次一次把所有数据拿出来\n",
    "        l = loss(net(X),y) # net(X) 为计算出来的线性回归的预测值\n",
    "        trainer.zero_grad() # 梯度清零\n",
    "        l.backward() \n",
    "        trainer.step()  # SGD优化器优化模型\n",
    "    for X, y in train_iter:\n",
    "        out = net(X)\n",
    "        batch_loss = loss(out, y)\n",
    "        train_loss += batch_loss.item() * X.shape[0]\n",
    "        num_samples += X.shape[0]\n",
    "        # 计算预测类别\n",
    "        pred = out.argmax(dim=1)\n",
    "        num_correct += (pred == y).sum().item()\n",
    "    avg_train_loss = train_loss / num_samples\n",
    "    accuracy = num_correct / num_samples\n",
    "    print(f'epoch:{epoch+1},cost:{l:f}, accuracy:{accuracy:.4f}')\n",
    "# 0.8268"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2a8d12e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试集平均loss: 0.480852\n",
      "测试集准确率: 0.8326\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# ========== 新增：用测试集评估模型性能 ==========\n",
    "test_loss = 0\n",
    "num_samples = 0\n",
    "num_correct = 0\n",
    "with torch.no_grad():\n",
    "    for X, y in test_iter:\n",
    "        out = net(X)\n",
    "        batch_loss = loss(out, y)\n",
    "        test_loss += batch_loss.item() * X.shape[0]\n",
    "        num_samples += X.shape[0]\n",
    "        # 计算预测类别\n",
    "        pred = out.argmax(dim=1)\n",
    "        num_correct += (pred == y).sum().item()\n",
    "    avg_test_loss = test_loss / num_samples\n",
    "    accuracy = num_correct / num_samples\n",
    "print(f\"测试集平均loss: {avg_test_loss:.6f}\")\n",
    "print(f\"测试集准确率: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd7a74d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
